\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Handwritten digits recognition with computer vision}

\author{\IEEEauthorblockN{Dastan Iyembergen}
\IEEEauthorblockA{\textit{Computer Science} \\
\textit{Nazarbayev University}\\
Nur-Sultan (Astana), Kazakhstan \\
dastan.iyembergen@nu.edu.kz}
}

\maketitle

\begin{abstract}
This document is a model and instructions for \LaTeX.
This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes, 
or Math in Paper Title or Abstract.
\end{abstract}

\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

\section{Introduction} 

When human sees numbers, human brain understands the meaning of this numbers. That is numbers carries meaningful information. For computer, an image of numbers is just a matrix of pixels. In order to obtain information from image we should process this image and recognize numbers. With the progress of computers people try to digitalize and automate systems. This is also related to digits. So, the problem is to obtain numerical information from digital image of handwritten digits, in order to use this information further. 

The example of such problem may be zip code recognition. In order to automate the delivery service, we need a system to recognize numbers from a digital image of a zip code. Formally, this task may be described as a function that takes an ‘rgb’ image of digits. The output of the function should be the list of numbers written on the image.  

There are already possible solutions for this problem. In terms of machine learning, it may be considered as a classification problem. Even so, every such system needs preprocessing steps and some application of image processing techniques. My approach is based on only the image processing techniques without the use of machine learning. Such approach better in terms of dataset requirements and training time, because my solution does not need dataset and training at all. Of course, such approach has own limitations on the input data, and it also requires long running time in the prediction step.  

\section{Previous works} 

In most of papers, the digit recognition is considered as a classification problem. Leon Bottou et al. have introduced the comparison of such classifiers \cite{bottou}. According to the results, the convolutional networks performed very high accuracy, but the runtime of such models were long. One of the main challenges were the feature extraction. The image pixels itself may be inputted as features. However, such model is sensitive to shifts. So, the features are extracted from curves, lines, their positions etc. The models were trained and tested with big databases of handwritten digits. 

Most of recognition techniques initially assume the input image to be preprocessed and one digit only per image. Denker et al. Introduced their approach for recognizing digits from zip code, where digits were extracted from an image \cite{denker}. In this work, segmentation, resizing, skeletonization processes were applied as a preprocessing. Then the preprocessed image was used in classifier model based on neural networks.  

Generally, classifiers based on neural networks illustrate very high accuracy, but the common issue of network-based classifiers is training time and requirement for big database. On the other hand, classifiers such as kNN require no training time, but require long prediction time. 

\section{Recognition with image processing techniques} 

\subsection{Problem specification} 

The task is to implement a function that will take a digital image and return the recognized digits. 
\begin{itemize}
\item Input: RGB image. 
\item Output: list of digits. 
\end{itemize} 

The requirements for the input image: 
\begin{itemize} 
\item The input image should be RGB image.  
\item The digit must be written with darker color than the background color.  
\item There should not be any other objects on the image except digits.  
\item The background must cover the full image. 
\item The background must be of one single color (for example: white paper) 
\item Each digit written on the paper must be a connected single component.  
\item The digits must be disjoint with each other. 
\item The thickness of digits must not be wide (pen will be ok) 
\item The boundaries of digits must be sharp 
\end{itemize} 

It is desirable that digits are written with black or blue pen on a white paper, as the function was tested with such inputs. 

The output of the function is list pf rows (also lists), where each row replresent the appropriate row on the image.

My approach is based on ‘pure’ image processing techniques, without machine learning.


\subsection{Structure of the solution}
The solution was implemented in Python 3. There are 5 '.py' files:
\begin{itemize}
    \item 'main.py': main script where we read the input image and call the main recognizer function by giving the image as an argument.
    \item 'digit\_recognizer.py': the script containing the main function.
    \item 'digit\_recognition\_tools.py': module containing helper functions to work with digit features.
    \item 'image\_processing\_tools.py': module containing the general image processing methods.
    \item 'coord\_operations.py': module to work with coordinate system objects (lines, points). Pixels are considered as points on the x-y plane.
\end{itemize} 

The 'digit\_recognizer.py' is divided into two functions: $recognize()$ and $digit\_recognize()$. The first function is main sunction, that does preprocessing steps and call the second one for each digit separately. the function $digit\_recognize()$ is responsible for recognizing a single digit and returning the prediction.

\subsection{preprocessing}


Converting to gray. The input RGB image was converted to the gray image, by applying the simple formula for each pixel: $p = \sqrt{r^2 + b^2 + c^2}$, where $r$, $g$, $b$ are the red, green and blue components of a pixel.

Taking the negative. In our case, the objects are darker than the background, but for the processing purposes, it is better that the objects are white while the background is black. So, the negative of the gray image from the previous step was taken by simple formua $q = 255-p$.

Converting to binary image. That was one of the challenging parts. Simple thresholding with static value was not applicable for all inputs. Dynamic thresholding such as taking 1/4 of the biggest difference of pixels also was not efficient, because there may be shadowed regions, that will overcome this threshold value. 
The possible solution for shadows was using edge detection techniques such as Sobel. A change in color around digit bowndaries is big, while a change in shadow regions is almost zero, because a shadow pixels change evenly. The issue with such method is that the edge detection detectes only the boundaries of digits.
The solution was to combine thresholding and edge detection together. The idea was to apply dilation on edge detected image, but only for those pixels which has value 1 on the thresholded image. This guarantees that the pixels outside the edges will not be extended.

Closing. The output of the previous algorithm may still have some gaps on the object bodies. to fill such gaps closing procedure was applied: two dilation operations followed by two erosion operations.

Segmentation. Firstly, the image was divided into rows of digits. This was done by finding the pixel rows that have no object pixels. Such pixel rows are counted as a separation between rows of digits.
Each digit row then is analyzed from left to right. To extract the connected regions, Bread First Search (BFS) was applied for each white pixel. Then the resulting component was cropped out from the image. Before the BFS algorithm, fegion filling procedure based on dilation was tried. However, the running time of the region filling procedure was very long comparing to the BFS.

After all these preprocessing procedures, each component (digit) is given as an argument for the next function $digit\_recognize()$.

On its turn, $digit\_recognize()$ also perform some preprocessing operations.

Resizing. The cropped image of a single digit is resized to fit into 75x75 square. Analyzing the images of the same dimensions is much easier than dealing with different shapes of images.

Defect filling. Even after the preprocessing steps done before, digits may have some defects (gaps). To fill such defects closing operation and hit or miss operation with appropriate mask were applied.

After all of these preprocessing steps, the digits images are ready for analyzing.


\subsection{Analyzing digits}

The analyzis was done in a decition tree manner. Each new extracted feature narrows down the possible outcomes, until we have only one possible outcome.

Holes. The first target was holes and their positions. The holes were extracted by running BFS on each black pixel. Based on these holes all digits that have hole are recognized:
\begin{itemize}
    \item If the number of holes is two, then it is 8.
    \item If there is one big hole, it is 0.
    \item If there is one hole at the upper part, it is 9.
    \item If there is one hole at the lower part, it is 6 or 2. the digits 6 and 2 are distinguished based on the size of the hole. The hole of the digit 6 is larger than the hole of the digit 2.
\end{itemize}

Next, the major and minor axises were measured. If the minor axis is equal to the thickness, this digit is 1.

The next step was to recognize 4. the digit 4 has two line ends on the upper part of the object. If we connect these two points, then the number of hole will be 1. To find the line ends hit or miss operation was applied with the appropriate mask.

Recognizing 7 with horizontal segment (-) at the center. Similarly to the previous step, line ends from left and right were found. Then the points were checked for the connection, if there is connection then it is line segment. If this line segment is lies approximately at the center, then the digit is 7.

Recognizing 3. 3 has 3 maximas from left. the maximas where detected with the same method as detecting line ends. Then the three points were analyzed with distance between them, and the connectness. These three points should not be connecte with a line, and the mean should be approximately at the middle part of the object.

Recognizing 1 and 7 (without line segment at the center)

\bibliographystyle{ieeetr}% Select the citation style % e.g. ieeetr
\bibliography{bibliography}% write the directory to the .bib file
\end{document}